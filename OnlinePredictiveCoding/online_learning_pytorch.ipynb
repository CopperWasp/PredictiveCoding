{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd  import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "import copy \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class error_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(error_module,self).__init__()\n",
    "        self.error_linear = nn.Linear(size,1)\n",
    "        self.Var_e = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x,prev_error):\n",
    "        x = self.error_linear(x) + self.Var_e * prev_error\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class classifier_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(classifier_module,self).__init__()\n",
    "        self.classifier_linear = nn.Linear(size,1)\n",
    "        self.Var_w = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x, prev_error):\n",
    "        x = self.classifier_linear(x) +  self.Var_w * prev_error \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MyHingeLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        hinge_loss = 1 - torch.mul(output, target)\n",
    "        hinge_loss[hinge_loss < 0] = 0\n",
    "        return hinge_loss\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class oco_classifier:\n",
    "    def __init__(self, size, C):\n",
    "        self.size = size\n",
    "        self.w = np.zeros(size)\n",
    "        self.C = C\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(self.w, x)\n",
    "\n",
    "    def update(self, x, y):\n",
    "        loss = np.maximum(0, 1.0 - y * np.dot(self.w, x))\n",
    "        if loss > 0:\n",
    "            self.w += np.minimum(self.C, loss/(np.square(np.linalg.norm(x))+ 1e-6)) * x * y\n",
    "        return loss\n",
    "\n",
    "    def reset(self):\n",
    "        self.w = np.zeros(self.size)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"german\", \"ionosphere\", \"spambase\", \"magic04\", \"a8a\"]\n",
    "root_path, extension = \"./datasets/\", \"_numeric\"\n",
    "\n",
    "\n",
    "def get_path(name):\n",
    "    '''returns a path pair to the preprocessed datasets\n",
    "    X and y csv files.'''\n",
    "    path = root_path + name + extension\n",
    "    return path + \"_X.csv\", path + \"_y.csv\"\n",
    "\n",
    "\n",
    "def read_dataset(X_path, y_path):\n",
    "    '''reads and returns numpy arrays in a given pair of paths for \n",
    "    X and y.'''\n",
    "    X = pd.read_csv(X_path).values\n",
    "    y = pd.read_csv(y_path)['0'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def simulate_varying(X):  # multivariate normal distribution\n",
    "    '''Get the data and generate a varying feature space pattern.\n",
    "    Possible concerns: thresholding messing up the distribution?'''\n",
    "    \n",
    "    # create a covariance matrix\n",
    "    cov = np.random.rand(num_features, num_features)\n",
    "    cov = np.dot(cov, cov.transpose())  # to have a positive semi-definite matrix\n",
    "    \n",
    "    # create a mean vector\n",
    "    mean = np.random.rand(len(X[0]))\n",
    "    \n",
    "    # sample from multivariate gaussian w/ given mean and cov\n",
    "    spaces = np.random.multivariate_normal(mean, cov, len(X))\n",
    "    \n",
    "    # threshold samples for 1-hot encoding\n",
    "    spaces[spaces < 0] = 0\n",
    "    spaces[spaces != 0] = 1\n",
    "\n",
    "    return spaces\n",
    "\n",
    "def simulate_random_varying(X): # discrete uniform distribution\n",
    "    matrix = np.random.randint(2, size=(len(X), len(X[0])))  \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def squash(x):\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    squared_x = np.square(norm_x)\n",
    "    s = squared_x/(1 + squared_x)\n",
    "    return s * x/(norm_x + 1e-5)\n",
    "\n",
    "def quant(x, l):  # l: num_layers, x:input\n",
    "    one_hot = []\n",
    "    for i in x:\n",
    "        if i != 0:\n",
    "            one_hot.append(1)\n",
    "        else:\n",
    "            one_hot.append(0)\n",
    "    one_hot = np.array(one_hot)\n",
    "    \n",
    "    qt = (one_hot - x) / (l-1)\n",
    "    qts = []\n",
    "    qts.append(one_hot)\n",
    "    #qts.append(squash(x))\n",
    "    for i in range(l-2):\n",
    "        qts.append(squash(x + qt * (l-2-i)))\n",
    "        #qts.append(x)\n",
    "        \n",
    "        \n",
    "    qts.append(x)    \n",
    "    \n",
    "    return np.array(qts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1.,  1.]), array([2788, 1812]))\n"
     ]
    }
   ],
   "source": [
    "X_path, y_path = get_path(\"spambase\")\n",
    "X, y = read_dataset(X_path, y_path)\n",
    "print(np.unique(y,return_counts=True))\n",
    "num_features = len(X[0])\n",
    "folds = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPNet(nn.Module):\n",
    "    def __init__(self,number_layers,size):\n",
    "        super(OPNet,self).__init__()\n",
    "        self.classifier_module = classifier_module(size)\n",
    "        self.number_layers = number_layers\n",
    "        self.error_modules = nn.ModuleList([error_module(size) for i in range(number_layers-1)])\n",
    "            \n",
    "    def forward(self,x):\n",
    "        predict= torch.zeros(1, 1).double()\n",
    "        errors = []\n",
    "        errors.append(torch.zeros(1, 1).double())\n",
    "        for i in range (self.number_layers - 1):\n",
    "            predict = self.error_modules[i](x[i], predict) \n",
    "            errors.append(torch.norm(predict - errors[-1]))\n",
    "        \n",
    "            \n",
    "        pred = self.classifier_module(x[-1], predict) \n",
    "        errors.append(torch.norm(pred - errors[-1]))\n",
    "        \n",
    "        return pred, errors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(w,lr,x,y,error_lin):\n",
    "    pred = np.dot(w,x)\n",
    "    #print(pred)\n",
    "    y_ = np.sign(pred)\n",
    "    loss = np.maximum(0, 1.0 - y * pred)\n",
    "    if loss > 0 :\n",
    "        w += np.minimum(lr , loss/np.square(np.linalg.norm(x) + 1e-5)) * y * x\n",
    "        \n",
    "    if y_ != y:\n",
    "        error_lin += 1\n",
    "    return error_lin, w\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.00060078e-01\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.00240288e-04\n",
      "  0.00000000e+00]]\n",
      "average_error_rate  0.1920217391304348\n",
      "average_error_rate_linear 0.30119565217391303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layers = 3\n",
    "error_val = []\n",
    "error_linear_val = []\n",
    "cum_loss = torch.zeros([1,1])\n",
    "cum_error_classifier = torch.zeros([1,1])\n",
    "cum_error_error1 = torch.zeros([1,1])\n",
    "cum_error_error2 = torch.zeros([1,1])\n",
    "#cum_error_error3 = torch.zeros([1,1])\n",
    "#cum_error_error4 = torch.zeros([1,1])\n",
    "for j in range(20): \n",
    "    error = 0\n",
    "    error_lin = 0\n",
    "    X , y = shuffle(X,y,random_state=0)\n",
    "    mask = simulate_random_varying(X)\n",
    "    X_ = copy.deepcopy(X)\n",
    "    X_ = X_ * mask\n",
    "    w = np.zeros(X.shape[1])\n",
    "    net = OPNet(layers,X.shape[1])\n",
    "    net = net.to(torch.double)\n",
    "    parameter = list(net.parameters())\n",
    "    criterion = MyHingeLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    writer = SummaryWriter()\n",
    "    for i in range(len(X)):\n",
    "        x = quant(X_[i],layers) \n",
    "        if i == 100 and j == 0:\n",
    "            print(x)\n",
    "        error_lin, w = linear_model(w,0.01,X_[i],y[i],error_lin)\n",
    "        #print(w)\n",
    "        x = torch.from_numpy(x).detach()\n",
    "        y_ = torch.from_numpy(y[i].reshape(1,1)).detach()\n",
    "        pred = net(x)\n",
    "        loss = criterion(pred[0], y_) + 0.001 * np.sum(pred[1])\n",
    "        cum_loss += loss\n",
    "        cum_error_classifier += pred[1][3]\n",
    "        cum_error_error1 += pred[1][1]\n",
    "        cum_error_error2 += pred[1][2]\n",
    "        \n",
    "        if torch.sign(pred[0]).detach().numpy()[0][0]!= y_:\n",
    "            error +=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if i%20 == 0:\n",
    "            #writer.add_scalar(\"loss \",cum_loss/(i+1), i)\n",
    "            #writer.add_scalar(\"error_error_module_1\",cum_error_error1/(i+1),i)\n",
    "            #writer.add_scalar(\"error_error_module_2\",cum_error_error2/(i+1),i)\n",
    "            #writer.add_scalar(\"error_error_module_3\",cum_error_error3/(i+1),i)\n",
    "            #writer.add_scalar(\"error_error_module_4\",cum_error_error4/(i+1),i)\n",
    "            #writer.add_scalar(\"error_classifier_module\",cum_error_classifier/(i+1),i)\n",
    "            #writer.add_histogram(\"error_module_1\",list(net.error_modules[0].parameters())[0],i)\n",
    "            #writer.add_histogram(\"error_module_2\",list(net.error_modules[1].parameters())[0],i)\n",
    "            #writer.add_histogram(\"error_module_3\",list(net.error_modules[2].parameters())[0],i)\n",
    "            #writer.add_histogram(\"error_module_4\",list(net.error_modules[3].parameters())[0],i)\n",
    "            #writer.add_histogram(\"classifier_module\",list(net.classifier_module.parameters())[0],i)\n",
    "    error_val.append(error/len(X))\n",
    "    error_linear_val.append(error_lin/len(X))\n",
    "writer.close()    \n",
    "print('average_error_rate ',np.average(error_val))\n",
    "print('average_error_rate_linear',np.average(error_linear_val))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights check\n",
    "#weight of norm each layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18217391304347827,\n",
       " 0.19130434782608696,\n",
       " 0.1973913043478261,\n",
       " 0.18608695652173912,\n",
       " 0.18478260869565216,\n",
       " 0.18456521739130435,\n",
       " 0.19108695652173913,\n",
       " 0.19391304347826088,\n",
       " 0.2126086956521739,\n",
       " 0.19804347826086957,\n",
       " 0.17891304347826087,\n",
       " 0.19695652173913045,\n",
       " 0.19847826086956522,\n",
       " 0.19282608695652173,\n",
       " 0.19456521739130433,\n",
       " 0.19782608695652174,\n",
       " 0.19804347826086957,\n",
       " 0.1743478260869565,\n",
       " 0.19782608695652174,\n",
       " 0.18869565217391304]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31782608695652176,\n",
       " 0.3080434782608696,\n",
       " 0.2995652173913044,\n",
       " 0.29478260869565215,\n",
       " 0.2995652173913044,\n",
       " 0.305,\n",
       " 0.29586956521739133,\n",
       " 0.2876086956521739,\n",
       " 0.2956521739130435,\n",
       " 0.3026086956521739,\n",
       " 0.30478260869565216,\n",
       " 0.3141304347826087,\n",
       " 0.30521739130434783,\n",
       " 0.3017391304347826,\n",
       " 0.29478260869565215,\n",
       " 0.3002173913043478,\n",
       " 0.3006521739130435,\n",
       " 0.29456521739130437,\n",
       " 0.31021739130434783,\n",
       " 0.2910869565217391]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_linear_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPNet(\n",
       "  (classifier_module): classifier_module(\n",
       "    (classifier_linear): Linear(in_features=57, out_features=1, bias=True)\n",
       "  )\n",
       "  (error_modules): ModuleList(\n",
       "    (0): error_module(\n",
       "      (error_linear): Linear(in_features=57, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): error_module(\n",
       "      (error_linear): Linear(in_features=57, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1920217391304348"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30119565217391303"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(error_linear_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
