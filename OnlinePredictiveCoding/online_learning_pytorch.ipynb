{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd  import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class error_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(error_module,self).__init__()\n",
    "        self.error_linear = nn.Linear(size,1)\n",
    "        self.Var_e = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x,prev_error):\n",
    "        x = self.error_linear(x) + self.Var_e * prev_error\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class classifier_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(classifier_module,self).__init__()\n",
    "        self.classifier_linear = nn.Linear(size,1)\n",
    "        self.Var_w = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x, prev_error):\n",
    "        x = self.classifier_linear(x) +  self.Var_w * prev_error \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MyHingeLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        hinge_loss = 1 - torch.mul(output, target)\n",
    "        hinge_loss[hinge_loss < 0] = 0\n",
    "        return hinge_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"german\", \"ionosphere\", \"spambase\", \"magic\", \"a8a\"]\n",
    "root_path, extension = \"./datasets/\", \"_numeric\"\n",
    "\n",
    "\n",
    "def get_path(name):\n",
    "    '''returns a path pair to the preprocessed datasets\n",
    "    X and y csv files.'''\n",
    "    path = root_path + name + extension\n",
    "    return path + \"_X.csv\", path + \"_y.csv\"\n",
    "\n",
    "\n",
    "def read_dataset(X_path, y_path):\n",
    "    '''reads and returns numpy arrays in a given pair of paths for \n",
    "    X and y.'''\n",
    "    X = pd.read_csv(X_path).values\n",
    "    y = pd.read_csv(y_path)['0'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def simulate_varying(X):  # multivariate normal distribution\n",
    "    '''Get the data and generate a varying feature space pattern.\n",
    "    Possible concerns: thresholding messing up the distribution?'''\n",
    "    \n",
    "    # create a covariance matrix\n",
    "    cov = np.random.rand(num_features, num_features) + 0.9\n",
    "    cov = np.dot(cov, cov.transpose())  # to have a positive semi-definite matrix\n",
    "    \n",
    "    # create a mean vector\n",
    "    mean = np.random.rand(len(X[0]))\n",
    "    \n",
    "    # sample from multivariate gaussian w/ given mean and cov\n",
    "    spaces = np.random.multivariate_normal(mean, cov, len(X))\n",
    "    \n",
    "    # threshold samples for 1-hot encoding\n",
    "    spaces[spaces < 0] = 0\n",
    "    spaces[spaces != 0] = 1\n",
    "\n",
    "    return spaces\n",
    "\n",
    "def simulate_random_varying(X): # discrete uniform distribution\n",
    "    matrix = np.random.randint(2, size=(len(X), len(X[0])))  \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def quant(x, l):  # l: num_layers, x:input\n",
    "    one_hot = []\n",
    "    for i in x:\n",
    "        if i != 0:\n",
    "            one_hot.append(1)\n",
    "        else:\n",
    "            one_hot.append(0)\n",
    "    one_hot = np.array(one_hot)\n",
    "    \n",
    "    qt = (one_hot - x) / (l-1)\n",
    "    qts = []\n",
    "    qts.append(one_hot)\n",
    "    \n",
    "    for i in range(l-2):\n",
    "        qts.append(x + qt * (l-2-i))\n",
    "        \n",
    "    qts.append(x)    \n",
    "    \n",
    "    return np.array(qts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1.,  1.]), array([300, 700]))\n"
     ]
    }
   ],
   "source": [
    "X_path, y_path = get_path(\"german\")\n",
    "X, y = read_dataset(X_path, y_path)\n",
    "print(np.unique(y,return_counts=True))\n",
    "num_features = len(X[0])\n",
    "folds = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPNet(nn.Module):\n",
    "    def __init__(self,number_layers,size):\n",
    "        super(OPNet,self).__init__()\n",
    "        self.classifier_module = classifier_module(size)\n",
    "        self.number_layers = number_layers\n",
    "        self.error_modules = nn.ModuleList([error_module(size) for i in range(number_layers-1)])\n",
    "            \n",
    "    def forward(self,x):\n",
    "        predict= torch.zeros(1, 1).double()\n",
    "        errors = []\n",
    "        errors.append(torch.zeros(1, 1).double())\n",
    "        for i in range (self.number_layers - 1):\n",
    "            predict = self.error_modules[i](x[i], predict) \n",
    "            errors.append(torch.norm(predict - errors[-1]))\n",
    "        \n",
    "            \n",
    "        pred = self.classifier_module(x[-1], predict) \n",
    "        errors.append(torch.norm(pred - errors[-1]))\n",
    "        \n",
    "        return pred, errors\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opcbackprop:\n",
    "    def __init__(self,number_layers,size,lr):\n",
    "        self.in_size = size\n",
    "        self.number_layers = number_layers\n",
    "        self.lr = lr\n",
    "        self.model = OPNet(number_layers,size)\n",
    "        self.criterion = MyHingeLoss()\n",
    "        self.optim = optim.SGD(self.model.parameters(), lr=lr)\n",
    "        \n",
    "    def predict(self,x,return_sum = True):\n",
    "        yhat = self.model(x)\n",
    "        return yhat[0]\n",
    "             \n",
    "    def update(self,x,y):\n",
    "        pred = self.predict(x)\n",
    "        loss = self.criterion(pred,y)\n",
    "        if torch.sign(pred).detach().numpy()[0][0]!= y:\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "        return loss\n",
    "            \n",
    "    def reset(self):\n",
    "        self.model = OPNet(number_layers,size)\n",
    "        self.optim = optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(w,lr,x,y,error_lin):\n",
    "    pred = np.dot(x,w)\n",
    "    y_ = np.sign(pred)\n",
    "    loss  = np.maximum(0, 1 - y * pred)\n",
    "    if loss > 0:\n",
    "        w += np.minimum(lr, loss/np.square(np.linalg.norm(x))) * y * x\n",
    "    if y_ != y:\n",
    "        error_lin += 1\n",
    "    return error_lin, w \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_error_rate  0.33925\n",
      "average_error_rate_linear 0.30150000000000005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# layers = 3\n",
    "# error_val = []\n",
    "# error_linear_val = []\n",
    "\n",
    "# #cum_error_error4 = torch.zeros([1,1])\n",
    "# for j in range(20): \n",
    "#     error = 0\n",
    "#     error_lin = 0\n",
    "#     X , y = shuffle(X,y,random_state=0)\n",
    "#     X_ = copy.deepcopy(X)\n",
    "    \n",
    "#     w = np.zeros(X.shape[1])\n",
    "#     net = OPNet(layers,X.shape[1])\n",
    "#     net = net.to(torch.double)\n",
    "#     parameter = list(net.parameters())\n",
    "#     criterion = MyHingeLoss()\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "#     writer = SummaryWriter()\n",
    "#     for i in range(len(X)):\n",
    "#         x= quant(X_[i],layers) \n",
    "#         #if i == 0 and j== 0:\n",
    "#         #    print(x)\n",
    "#         #    break\n",
    "#         error_lin, w = linear_model(w,0.01,X_[i],y[i],error_lin)\n",
    "#         x = torch.from_numpy(x).detach()\n",
    "#         y_ = torch.from_numpy(y[i].reshape(1,1)).detach()\n",
    "#         #rand_var = torch.tensor(np.zeros_like(x))\n",
    "#         #print(rand_var)\n",
    "#         #writer.add_graph(net,rand_var)\n",
    "#         pred = net(x)\n",
    "#         loss = criterion(pred[0], y_) #+ 0.1 * np.sum(pred[1])\n",
    "#         cum_loss += loss\n",
    "#         cum_error_classifier += pred[1][3]\n",
    "#         cum_error_error1 += pred[1][1]\n",
    "#         cum_error_error2 += pred[1][2]\n",
    "#         #cum_error_error3 += pred[1][3]\n",
    "#         #cum_error_error4 += pred[1][4]\n",
    "#         if torch.sign(pred[0]).detach().numpy()[0][0]!= y_:\n",
    "#             error +=1\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         if i%20 == 0:\n",
    "#             writer.add_scalar(\"loss \",cum_loss/(i+1), i)\n",
    "#             writer.add_scalar(\"error_error_module_1\",cum_error_error1/(i+1),i)\n",
    "#             writer.add_scalar(\"error_error_module_2\",cum_error_error2/(i+1),i)\n",
    "#             #writer.add_scalar(\"error_error_module_3\",cum_error_error3/(i+1),i)\n",
    "#             #writer.add_scalar(\"error_error_module_4\",cum_error_error4/(i+1),i)\n",
    "#             writer.add_scalar(\"error_classifier_module\",cum_error_classifier/(i+1),i)\n",
    "#             writer.add_histogram(\"error_module_1\",list(net.error_modules[0].parameters())[0],i)\n",
    "#             writer.add_histogram(\"error_module_2\",list(net.error_modules[1].parameters())[0],i)\n",
    "#             #writer.add_histogram(\"error_module_3\",list(net.error_modules[2].parameters())[0],i)\n",
    "#             #writer.add_histogram(\"error_module_4\",list(net.error_modules[3].parameters())[0],i)\n",
    "#             #writer.add_histogram(\"classifier_module\",list(net.classifier_module.parameters())[0],i)\n",
    "#     error_val.append(error/len(X))\n",
    "#     error_linear_val.append(error_lin/len(X))\n",
    "# writer.close()    \n",
    "# print('average_error_rate ',np.average(error_val))\n",
    "# print('average_error_rate_linear',np.average(error_linear_val))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights check\n",
    "#weight of norm each layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.326,\n",
       " 0.349,\n",
       " 0.339,\n",
       " 0.341,\n",
       " 0.33,\n",
       " 0.346,\n",
       " 0.353,\n",
       " 0.362,\n",
       " 0.328,\n",
       " 0.349,\n",
       " 0.314,\n",
       " 0.32,\n",
       " 0.33,\n",
       " 0.334,\n",
       " 0.335,\n",
       " 0.347,\n",
       " 0.353,\n",
       " 0.352,\n",
       " 0.357,\n",
       " 0.32]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.301,\n",
       " 0.307,\n",
       " 0.301,\n",
       " 0.302,\n",
       " 0.301,\n",
       " 0.302,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.302,\n",
       " 0.3,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.3,\n",
       " 0.304,\n",
       " 0.301,\n",
       " 0.301,\n",
       " 0.301]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_linear_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPNet(\n",
       "  (classifier_module): classifier_module(\n",
       "    (classifier_linear): Linear(in_features=24, out_features=1, bias=True)\n",
       "  )\n",
       "  (error_modules): ModuleList(\n",
       "    (0): error_module(\n",
       "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): error_module(\n",
       "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
