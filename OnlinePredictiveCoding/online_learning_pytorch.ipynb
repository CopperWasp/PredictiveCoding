{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd  import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class error_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(error_module,self).__init__()\n",
    "        self.error_linear = nn.Linear(size,1)\n",
    "        self.Var_e = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x,prev_error):\n",
    "        x = self.error_linear(x) + self.Var_e * prev_error\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class classifier_module(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(classifier_module,self).__init__()\n",
    "        self.classifier_linear = nn.Linear(size,1)\n",
    "        self.Var_w = Variable(torch.ones(1, 1), requires_grad=True)\n",
    "    def forward(self,x, prev_error):\n",
    "        x = self.classifier_linear(x) + self.Var_w * prev_error \n",
    "        \n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"german\", \"ionosphere\", \"spambase\", \"magic\", \"a8a\"]\n",
    "root_path, extension = \"./datasets/\", \"_numeric\"\n",
    "\n",
    "\n",
    "def get_path(name):\n",
    "    '''returns a path pair to the preprocessed datasets\n",
    "    X and y csv files.'''\n",
    "    path = root_path + name + extension\n",
    "    return path + \"_X.csv\", path + \"_y.csv\"\n",
    "\n",
    "\n",
    "def read_dataset(X_path, y_path):\n",
    "    '''reads and returns numpy arrays in a given pair of paths for \n",
    "    X and y.'''\n",
    "    X = pd.read_csv(X_path).values\n",
    "    y = pd.read_csv(y_path)['0'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def simulate_varying(X):  # multivariate normal distribution\n",
    "    '''Get the data and generate a varying feature space pattern.\n",
    "    Possible concerns: thresholding messing up the distribution?'''\n",
    "    \n",
    "    # create a covariance matrix\n",
    "    cov = np.random.rand(num_features, num_features)\n",
    "    cov = np.dot(cov, cov.transpose())  # to have a positive semi-definite matrix\n",
    "    \n",
    "    # create a mean vector\n",
    "    mean = np.random.rand(len(X[0]))\n",
    "    \n",
    "    # sample from multivariate gaussian w/ given mean and cov\n",
    "    spaces = np.random.multivariate_normal(mean, cov, len(X))\n",
    "    \n",
    "    # threshold samples for 1-hot encoding\n",
    "    spaces[spaces < 0] = 0\n",
    "    spaces[spaces != 0] = 1\n",
    "\n",
    "    return spaces\n",
    "\n",
    "def simulate_random_varying(X): # discrete uniform distribution\n",
    "    matrix = np.random.randint(2, size=(len(X), len(X[0])))  \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def quant(x, l):  # l: num_layers, x:input\n",
    "    one_hot = []\n",
    "    for i in x:\n",
    "        if i != 0:\n",
    "            one_hot.append(1)\n",
    "        else:\n",
    "            one_hot.append(0)\n",
    "    one_hot = np.array(one_hot)\n",
    "    \n",
    "    qt = (one_hot-x)/l\n",
    "    qts = []\n",
    "    qts.append(one_hot)\n",
    "    \n",
    "    for i in range(l):\n",
    "        qts.append(x + qt * (l-i+1))\n",
    "        \n",
    "    qts.append(x)    \n",
    "    \n",
    "    return np.array(qts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1.,  1.]), array([300, 700]))\n"
     ]
    }
   ],
   "source": [
    "X_path, y_path = get_path(\"german\")\n",
    "X, y = read_dataset(X_path, y_path)\n",
    "print(np.unique(y,return_counts=True))\n",
    "num_features = len(X[0])\n",
    "folds = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPNet(nn.Module):\n",
    "    def __init__(self,number_layers,size):\n",
    "        super(OPNet,self).__init__()\n",
    "        self.classifier_module = classifier_module(size)\n",
    "        self.number_layers = number_layers\n",
    "        self.error_modules = nn.ModuleList([error_module(size) for i in range(number_layers-1)])\n",
    "            \n",
    "    def forward(self,x):\n",
    "        predict= torch.zeros(1, 1).double()\n",
    "        errors = []\n",
    "        errors.append(torch.zeros(1, 1).double())\n",
    "        for i in range (self.number_layers - 1):\n",
    "            predict = self.error_modules[i](x[i], predict) \n",
    "            errors.append(predict - errors[-1])\n",
    "        \n",
    "            \n",
    "        pred = self.classifier_module(x[-1], predict) \n",
    "        errors.append(pred - errors[-1])\n",
    "        \n",
    "        return pred, errors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPNet(\n",
      "  (classifier_module): classifier_module(\n",
      "    (classifier_linear): Linear(in_features=24, out_features=1, bias=True)\n",
      "  )\n",
      "  (error_modules): ModuleList(\n",
      "    (0): error_module(\n",
      "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
      "    )\n",
      "    (1): error_module(\n",
      "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
      "    )\n",
      "    (2): error_module(\n",
      "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
      "    )\n",
      "    (3): error_module(\n",
      "      (error_linear): Linear(in_features=24, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l = 5\n",
    "net = OPNet(l,X.shape[1])\n",
    "net = net.to(torch.double)\n",
    "print(net)\n",
    "parameter = list(net.parameters())\n",
    "criterion = nn.HingeEmbeddingLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_rate :  0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "error=0\n",
    "for i in range(len(X)):\n",
    "    x= quant(X[i],l)\n",
    "    x = torch.from_numpy(x)\n",
    "    y_ = torch.from_numpy(y[i].reshape(1,1))\n",
    "    pred = net(x)\n",
    "    if torch.sign(pred[0]).detach().numpy()[0][0]!= y_:\n",
    "        error +=1\n",
    "    loss = criterion(torch.sign(pred[0]), y_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"error_rate : \",error/len(X))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
