{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variation Types in Feature Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparison of Performance of a Traditional Learner in Different Variation Patterns\n",
    "We try to observe any recurring pattern in terms of performance when variation pattern differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german varying_gaussian + 0.5 opcbackprop 0.37729999999999997\n",
      "german varying_gaussian + 0.5 hinge_oco 0.50515\n",
      "ionosphere varying_gaussian + 0.5 opcbackprop 0.4164285714285715\n",
      "ionosphere varying_gaussian + 0.5 hinge_oco 0.5207142857142857\n",
      "spambase varying_gaussian + 0.5 opcbackprop 0.2695\n",
      "spambase varying_gaussian + 0.5 hinge_oco 0.4943369565217391\n",
      "svmguide3 varying_gaussian + 0.5 opcbackprop 0.34722445695897025\n",
      "svmguide3 varying_gaussian + 0.5 hinge_oco 0.44678197908286404\n",
      "wpbc varying_gaussian + 0.5 opcbackprop 0.35025252525252526\n",
      "wpbc varying_gaussian + 0.5 hinge_oco 0.42904040404040406\n",
      "wdbc varying_gaussian + 0.5 opcbackprop 0.32451669595782073\n",
      "wdbc varying_gaussian + 0.5 hinge_oco 0.5599297012302284\n",
      "magic04 varying_gaussian + 0.5 opcbackprop 0.38561175666438824\n",
      "magic04 varying_gaussian + 0.5 hinge_oco 0.4899521531100479\n",
      "a8a varying_gaussian + 0.5 opcbackprop 0.27826929855481136\n",
      "a8a varying_gaussian + 0.5 hinge_oco 0.4347043531899894\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b9053f0675f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-0b9053f0675f>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(results, instances_track, data_set)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdata_opc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"opcbackprop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdata_hinge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hinge_oco\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstances_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"opcbackprop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0my_opc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_opc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0my_hinge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hinge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import dataloader as dl\n",
    "import numpy as np\n",
    "import trainer\n",
    "import parameters as p\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "datasets = ['german', 'ionosphere', 'spambase','svmguide3','wpbc','wdbc','magic04','a8a']\n",
    "model_types = ['opcbackprop','hinge_oco']\n",
    "\n",
    "\n",
    "# initialize results dict\n",
    "results = {}\n",
    "masks = {}\n",
    "occurrences = {}\n",
    "instances_track = {}\n",
    "for dataset in datasets:\n",
    "    results[dataset] = {}\n",
    "    masks[dataset] = {}\n",
    "    occurrences[dataset] = {}\n",
    "    instances_track[dataset] ={}\n",
    "    for model_type in model_types :\n",
    "        results[dataset][model_type] = 0\n",
    "        masks[dataset][model_type] = []\n",
    "        \n",
    "for scenario in p.scenarios:\n",
    "    for dataset_name in p.datasets:\n",
    "        for model_type in model_types:\n",
    "            Xpath, ypath = dl.get_path(dataset_name)\n",
    "            X, y = dl.read_dataset(Xpath, ypath)\n",
    "            num_features = len(X[0])\n",
    "            m = p.models[model_type](num_features, p.learning_rate, p.num_layers[0])\n",
    "            fold_errors, fold_cum_error, instances, fold_losses, fold_weights, fold_masks = trainer.cross_validation(X, y, m, p.folds, p.scenarios[scenario],p.cov_strength[scenario])\n",
    "            masks[dataset_name][model_type] = fold_masks\n",
    "            results[dataset_name][model_type] = fold_cum_error\n",
    "            instances_track[dataset_name][model_type] = instances\n",
    "            print(dataset_name, scenario, model_type, np.mean(fold_errors))\n",
    "    print()    \n",
    "\n",
    "    \n",
    "# plot results for each dataset\n",
    "'''\n",
    "for dataset_name in datasets:\n",
    "    plt.title(dataset_name)\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.bar(results[dataset_name].keys(), results[dataset_name].values())\n",
    "    plt.show()\n",
    "'''\n",
    "\n",
    "'''\n",
    "df = pd.DataFrame(results).T\n",
    "ax = df.plot(kind=\"bar\",figsize=(10, 10),title =\"Analysis with Num_layers\")\n",
    "ax.set_xlabel(\"Dataset\")\n",
    "ax.set_ylabel(\"Error_rate\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('number_of_layers.png')\n",
    "'''\n",
    "\n",
    "def plot(results,instances_track,data_set):\n",
    "    data_opc = np.array(results[data_set][\"opcbackprop\"])\n",
    "    data_hinge = np.array(results[data_set][\"hinge_oco\"])\n",
    "    x = instances_track[data_set][\"opcbackprop\"]\n",
    "    y_opc = np.average(data_opc,axis=0)\n",
    "    y_hinge = np.average(data_hinge,axis=0)\n",
    "    y_err_opc = np.std(data_opc,axis=0)\n",
    "    y_err_hinge = np.std(data_hinge,axis=0)\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.errorbar(x, y_opc,\n",
    "            yerr=y_err_opc,\n",
    "            fmt='-o')\n",
    "    ax.errorbar(x, y_hinge,\n",
    "            yerr=y_err_hinge,\n",
    "            fmt='-or')\n",
    "\n",
    "    ax.set_xlabel('instances')\n",
    "    ax.set_ylabel('error_rate')\n",
    "    ax.set_title(data_set + \" error plot \")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "for data_set in datasets:\n",
    "    plot(results,instances,data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in masks:\n",
    "    for scenario in p.scenarios:\n",
    "        sum_masks = copy.deepcopy(masks[key][scenario][0])\n",
    "        for i in range(1, len(masks[key][scenario])):\n",
    "            sum_masks += masks[key][scenario][i]\n",
    "\n",
    "        avg_sum_masks =  sum_masks / len(masks[key][scenario])\n",
    "        avg_sum_masks = np.sum(avg_sum_masks, axis=0) / len(sum_masks)\n",
    "        occurrences[key][scenario] = avg_sum_masks\n",
    "        \n",
    "        plt.title(key + scenario)\n",
    "        plt.plot(occurrences[key][scenario])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have made two observations so far:**\n",
    "1. Performance in non-uniformly distributed variation in feature spaces is worse than uniform.\n",
    "2. Checking the average availability frequency of features don't immediately give an explanation about this.\n",
    "\n",
    "After this, Jeev suggested to look at the co-occurrences of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs. Feature Co-Occurrence Patterns\n",
    "Let us take the *german* dataset and see how feature co-occurrences look like in different versions of the variation.\n",
    "To do this, we first merge the masks from different folds of cross-validation we have.\n",
    "Masks represent the feature availability in a training instance, therefore, useful when we are working on structures of feature spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cov_mat(masks, dataset, setting):\n",
    "    m = masks[dataset][setting]\n",
    "    joint_mask = m[0]\n",
    "    \n",
    "    for i in range(1, len(m)):\n",
    "        joint_mask = np.vstack((joint_mask, m[i]))\n",
    "    \n",
    "    cov_mat = np.cov(joint_mask.T)\n",
    "    sns.heatmap(cov_mat)\n",
    "    plt.show()\n",
    "    return cov_mat\n",
    "\n",
    "\n",
    "settings = ['full', 'varying_uniform', 'varying_gaussian']\n",
    "\n",
    "for dataset in datasets:\n",
    "    for setting in settings:\n",
    "        print(dataset)\n",
    "        show_cov_mat(masks, dataset, setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that an important is that varying feature spaces distribution in a uniform fashion have low covariance -> feature co-occurrence. This means feature occurrences don't follow a particular pattern. On the other hand, for gaussian, there exists various amounts of covariance between features, starting to form a pattern. This seems to be making learning harder for some reason.\n",
    "\n",
    "**Note:** In both cases, the diagonal of the matrix seems to be 0.25. Diagonals of a covariance matrix are the variances of the components of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Between the Amount of Covariance in Varying Gaussian and the Traditional Model Performance\n",
    "In this section, we take the generator of varying_gaussian and modify it in a way that it removes features in different levels of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results,instances_track,data_set):\n",
    "    data_opc = np.array(results[data_set][\"opcbackprop\"])\n",
    "    data_hinge = np.array(results[data_set][\"hinge_oco\"])\n",
    "    x = instances_track[data_set][\"opcbackprop\"]\n",
    "    y_opc = np.average(data_opc,axis=0)\n",
    "    y_hinge = np.average(data_hinge,axis=0)\n",
    "    y_err_opc = np.std(data_opc,axis=0)\n",
    "    y_err_hinge = np.std(data_hinge,axis=0)\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.errorbar(x, y_opc,\n",
    "            yerr=y_err_opc,\n",
    "            fmt='-o',label='opc_backprop')\n",
    "    ax.errorbar(x, y_hinge,\n",
    "            yerr=y_err_hinge,\n",
    "            fmt='-or',label='hinge_oco')\n",
    "    \n",
    "\n",
    "    ax.set_xlabel('instances')\n",
    "    ax.set_ylabel('error_rate')\n",
    "    ax.set_title(data_set + \" error plot \")\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for data_set in datasets:\n",
    "    plot(results,instances_track,data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
