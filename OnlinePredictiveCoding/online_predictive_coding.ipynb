{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Predictive Coding\n",
    "In this notebook, we implement the first version of our prototype for learning from varying feature spaces.\n",
    "\n",
    "## Model Design\n",
    "- add the plot we have on the desktop computer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class error_module:\n",
    "    def __init__(self, size, lr):\n",
    "        self.w = np.zeros(size)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(self.w, x)\n",
    "    \n",
    "    def update(self, x, y):\n",
    "        yhat = self.predict(x)  # regression\n",
    "        loss = 0.5 * (y - yhat)**2\n",
    "        self.w += self.lr * (y - yhat)\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "class classifier_module:\n",
    "    def __init__(self, size, lr):\n",
    "        self.w = np.zeros(size)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(self.w, x)\n",
    "\n",
    "    def update(self, x, y):\n",
    "        loss = np.maximum(0, 1.0 - y * np.dot(self.w, x))\n",
    "        if loss > 0: self.w += x * y * self.lr\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"german\", \"ionosphere\", \"spambase\", \"magic\", \"a8a\"]\n",
    "root_path, extension = \"./datasets/\", \"_numeric\"\n",
    "\n",
    "\n",
    "def get_path(name):\n",
    "    '''returns a path pair to the preprocessed datasets\n",
    "    X and y csv files.'''\n",
    "    path = root_path + name + extension\n",
    "    return path + \"_X.csv\", path + \"_y.csv\"\n",
    "\n",
    "\n",
    "def read_dataset(X_path, y_path):\n",
    "    '''reads and returns numpy arrays in a given pair of paths for \n",
    "    X and y.'''\n",
    "    X = pd.read_csv(X_path).values\n",
    "    y = pd.read_csv(y_path)['0'].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def simulate_varying(X):  # multivariate normal distribution\n",
    "    '''Get the data and generate a varying feature space pattern.\n",
    "    Possible concerns: thresholding messing up the distribution?'''\n",
    "    \n",
    "    # create a covariance matrix\n",
    "    cov = np.random.rand(num_features, num_features)\n",
    "    cov = np.dot(cov, cov.transpose())  # to have a positive semi-definite matrix\n",
    "    \n",
    "    # create a mean vector\n",
    "    mean = np.random.rand(len(X[0]))\n",
    "    \n",
    "    # sample from multivariate gaussian w/ given mean and cov\n",
    "    spaces = np.random.multivariate_normal(mean, cov, len(X))\n",
    "    \n",
    "    # threshold samples for 1-hot encoding\n",
    "    spaces[spaces < 0] = 0\n",
    "    spaces[spaces != 0] = 1\n",
    "\n",
    "    return spaces\n",
    "\n",
    "\n",
    "def simulate_random_varying(X): # discrete uniform distribution\n",
    "    matrix = np.random.randint(2, size=(len(X), len(X[0])))  \n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "def quant(x, l):  # l: num_layers, x:input\n",
    "    one_hot = []\n",
    "    for i in x:\n",
    "        if i != 0:\n",
    "            one_hot.append(1)\n",
    "        else:\n",
    "            one_hot.append(0)\n",
    "    one_hot = np.array(one_hot)\n",
    "    \n",
    "    qt = (one_hot-x)/l\n",
    "    \n",
    "    return one_hot, x+qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path, y_path = get_path(\"german\")\n",
    "X, y = read_dataset(X_path, y_path)\n",
    "num_features = len(X[0])\n",
    "folds = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.3922\n"
     ]
    }
   ],
   "source": [
    "# multivariate gaussian mask with threshold 0\n",
    "\n",
    "fold_error_rates = []\n",
    "predictions = []\n",
    "losses = []\n",
    "\n",
    "for f in range(folds):\n",
    "    error_count = 0\n",
    "    \n",
    "    # shuffle for each fold\n",
    "    l = list(range(len(X)))\n",
    "    np.random.shuffle(l)\n",
    "    X, y = X[l], y[l]\n",
    "    mask = simulate_varying(X)  # multivariate\n",
    "    \n",
    "    # initialize model\n",
    "    model = classifier_module(num_features, learning_rate)\n",
    "    #model = error_module(num_features, learning_rate)\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        # predict and suffer\n",
    "        yhat = model.predict(X[i] * mask[i])\n",
    "        loss = model.update(X[i] * mask[i], y[i])\n",
    "        \n",
    "        # bookkeeping\n",
    "        predictions.append(yhat)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if np.sign(yhat) != y[i]:\n",
    "            error_count += 1\n",
    "        \n",
    "    fold_error_rates.append(error_count/len(X))\n",
    "\n",
    "print(learning_rate, np.mean(fold_error_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlinePredictiveCoding:\n",
    "    def __init__(self, num_layers, num_features):\n",
    "        self.classifier = classifier_module(num_features, learning_rate)\n",
    "        \n",
    "        self.error_modules = []\n",
    "        for i in range(num_layers - 1):\n",
    "            self.error_modules.append(error_module(num_features, learning_rate))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "opc = OnlinePredictiveCoding(3, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
